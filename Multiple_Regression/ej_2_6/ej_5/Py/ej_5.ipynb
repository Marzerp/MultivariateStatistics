{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc238010-dfde-4f74-98ab-6a88a418b643",
   "metadata": {},
   "source": [
    "Ejercicio 5: Para los datos del ejercicio 1 de la liga de Futbol. Realizar el ejercicio Python\n",
    "\n",
    "SE OMITEN RESULTADOS, PORQUE SON LOS MISMOS QUE USANDO R.\n",
    "\n",
    "A) Usar el algoritmo de selección hacia adelante para seleccionar un modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00fbf22-f7aa-4039-945a-8d7a08ef3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados:\n",
      "    y    x1    x2    x3    x4  x5   x6    x7    x8    x9\n",
      "0  10  2113  1985  38.9  64.7   4  868  59.7  2205  1917\n",
      "1  11  2003  2855  38.8  61.3   3  615  55.0  2096  1575\n",
      "2  11  2957  1737  40.1  60.0  14  914  65.6  1847  2175\n",
      "3  13  2285  2905  41.6  45.3  -4  957  61.4  1903  2476\n",
      "4  10  2971  1666  39.2  53.8  15  836  66.1  1457  1866\n",
      "\n",
      "Dimensión de los datos: (28, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar los datos\n",
    "datos = pd.read_csv(\"Liga_nacional_de_futbol.csv\")\n",
    "print(\"Datos cargados:\")\n",
    "print(datos.head())\n",
    "print(f\"\\nDimensión de los datos: {datos.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f563c06-3d50-42e2-b366-9bcf92e2704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTODO PRINCIPAL:\n",
      "==============================\n",
      "Iniciando selección hacia adelante...\n",
      "==================================================\n",
      "Paso 1: Se agregó 'x8' (p-valor = 0.0000)\n",
      "   R² ajustado: 0.5272, AIC: 130.25\n",
      "Paso 2: Se agregó 'x2' (p-valor = 0.0002)\n",
      "   R² ajustado: 0.7227, AIC: 116.20\n",
      "Paso 3: Se agregó 'x7' (p-valor = 0.0378)\n",
      "   R² ajustado: 0.7596, AIC: 113.06\n",
      "\n",
      "Criterio de parada: Ninguna variable restante tiene p-valor < 0.05\n",
      "\n",
      "==================================================\n",
      "Selección finalizada\n",
      "Variables seleccionadas: ['x8', 'x2', 'x7']\n",
      "Fórmula final: y ~ x8 + x2 + x7\n",
      "\n",
      "Resumen del modelo final:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.760\n",
      "Method:                 Least Squares   F-statistic:                     29.44\n",
      "Date:                Sun, 07 Sep 2025   Prob (F-statistic):           3.27e-08\n",
      "Time:                        22:48:10   Log-Likelihood:                -52.532\n",
      "No. Observations:                  28   AIC:                             113.1\n",
      "Df Residuals:                      24   BIC:                             118.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.8084      7.901     -0.229      0.821     -18.115      14.498\n",
      "x8            -0.0048      0.001     -3.771      0.001      -0.007      -0.002\n",
      "x2             0.0036      0.001      5.177      0.000       0.002       0.005\n",
      "x7             0.1940      0.088      2.198      0.038       0.012       0.376\n",
      "==============================================================================\n",
      "Omnibus:                        0.665   Durbin-Watson:                   1.492\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.578\n",
      "Skew:                           0.321   Prob(JB):                        0.749\n",
      "Kurtosis:                       2.712   Cond. No.                     7.42e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.42e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Función para selección hacia adelante basada en p-valores\n",
    "def seleccion_adelante_pvalor(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Implementa selección hacia adelante basada en p-valores\n",
    "    \"\"\"\n",
    "    variables_disponibles = [col for col in data.columns if col != 'y']\n",
    "    variables_seleccionadas = []\n",
    "    \n",
    "    print(\"Iniciando selección hacia adelante...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Modelo inicial (solo intercepto) - CORREGIDO\n",
    "    X = np.ones((len(data), 1))  # Matriz de unos para el intercepto\n",
    "    y = data['y']\n",
    "    modelo_actual = sm.OLS(y, X).fit()\n",
    "    \n",
    "    paso = 1\n",
    "    \n",
    "    while variables_disponibles:\n",
    "        mejor_pvalor = float('inf')\n",
    "        mejor_variable = None\n",
    "        mejor_modelo = None\n",
    "        \n",
    "        # Probar cada variable disponible\n",
    "        for variable in variables_disponibles:\n",
    "            # Crear matriz de diseño con variables actuales + nueva variable\n",
    "            if variables_seleccionadas:\n",
    "                X_temp = data[variables_seleccionadas + [variable]].copy()\n",
    "            else:\n",
    "                X_temp = data[[variable]].copy()\n",
    "            \n",
    "            # Agregar constante\n",
    "            X_temp = sm.add_constant(X_temp)\n",
    "            \n",
    "            # Ajustar modelo temporal\n",
    "            modelo_temp = sm.OLS(y, X_temp).fit()\n",
    "            \n",
    "            # Obtener p-valor de la nueva variable\n",
    "            pvalor_nuevo = modelo_temp.pvalues[variable]\n",
    "            \n",
    "            # Verificar si es la mejor variable\n",
    "            if pvalor_nuevo < mejor_pvalor:\n",
    "                mejor_pvalor = pvalor_nuevo\n",
    "                mejor_variable = variable\n",
    "                mejor_modelo = modelo_temp\n",
    "        \n",
    "        # Verificar criterio de parada\n",
    "        if mejor_pvalor > alpha:\n",
    "            print(f\"\\nCriterio de parada: Ninguna variable restante tiene p-valor < {alpha}\")\n",
    "            break\n",
    "        \n",
    "        # Agregar la mejor variable al modelo\n",
    "        variables_seleccionadas.append(mejor_variable)\n",
    "        variables_disponibles.remove(mejor_variable)\n",
    "        modelo_actual = mejor_modelo\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"Paso {paso}: Se agregó '{mejor_variable}' (p-valor = {mejor_pvalor:.4f})\")\n",
    "        print(f\"   R² ajustado: {modelo_actual.rsquared_adj:.4f}, AIC: {modelo_actual.aic:.2f}\")\n",
    "        \n",
    "        paso += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Selección finalizada\")\n",
    "    print(f\"Variables seleccionadas: {variables_seleccionadas}\")\n",
    "    print(f\"Fórmula final: y ~ {' + '.join(variables_seleccionadas)}\")\n",
    "    print(\"\\nResumen del modelo final:\")\n",
    "    print(modelo_actual.summary())\n",
    "    \n",
    "    return modelo_actual, variables_seleccionadas\n",
    "\n",
    "# Versión simplificada y más robusta\n",
    "def seleccion_adelante_simple(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Implementación simplificada de selección hacia adelante\n",
    "    \"\"\"\n",
    "    variables = [col for col in data.columns if col != 'y']\n",
    "    seleccionadas = []\n",
    "    y = data['y']\n",
    "    \n",
    "    print(\"\\nMÉTODO SIMPLIFICADO:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Modelo inicial con solo intercepto\n",
    "    X_const = sm.add_constant(pd.DataFrame())  # DataFrame vacío con constante\n",
    "    modelo_actual = sm.OLS(y, X_const).fit()\n",
    "    \n",
    "    paso = 1\n",
    "    \n",
    "    while variables:\n",
    "        mejor_p = 1.0\n",
    "        mejor_var = None\n",
    "        \n",
    "        for var in variables:\n",
    "            # Crear matriz con variables seleccionadas + nueva variable\n",
    "            if seleccionadas:\n",
    "                X_temp = data[seleccionadas + [var]]\n",
    "            else:\n",
    "                X_temp = data[[var]]\n",
    "            \n",
    "            X_temp = sm.add_constant(X_temp)\n",
    "            modelo_temp = sm.OLS(y, X_temp).fit()\n",
    "            \n",
    "            p_val = modelo_temp.pvalues[var]\n",
    "            \n",
    "            if p_val < mejor_p:\n",
    "                mejor_p = p_val\n",
    "                mejor_var = var\n",
    "                mejor_modelo = modelo_temp\n",
    "        \n",
    "        if mejor_p > alpha:\n",
    "            print(f\"Parando: {mejor_var} tiene p-valor {mejor_p:.4f} > {alpha}\")\n",
    "            break\n",
    "        \n",
    "        seleccionadas.append(mejor_var)\n",
    "        variables.remove(mejor_var)\n",
    "        modelo_actual = mejor_modelo\n",
    "        \n",
    "        print(f\"Paso {paso}: Agregada {mejor_var} (p={mejor_p:.4f}), R²-adj: {modelo_actual.rsquared_adj:.4f}\")\n",
    "        paso += 1\n",
    "    \n",
    "    # Ajustar modelo final con todas las variables seleccionadas\n",
    "    if seleccionadas:\n",
    "        X_final = sm.add_constant(data[seleccionadas])\n",
    "        modelo_final = sm.OLS(y, X_final).fit()\n",
    "    else:\n",
    "        modelo_final = modelo_actual  # Solo intercepto\n",
    "    \n",
    "    print(f\"\\nVariables seleccionadas: {seleccionadas}\")\n",
    "    print(\"Resumen del modelo final:\")\n",
    "    print(modelo_final.summary())\n",
    "    \n",
    "    return modelo_final, seleccionadas\n",
    "\n",
    "# Método alternativo usando solo intercepto inicial\n",
    "def seleccion_adelante_intercepto(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Método que comienza con solo intercepto\n",
    "    \"\"\"\n",
    "    variables = [col for col in data.columns if col != 'y']\n",
    "    seleccionadas = []\n",
    "    y = data['y']\n",
    "    \n",
    "    print(\"\\nMÉTODO CON INTERCEPTO:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    paso = 1\n",
    "    \n",
    "    while variables:\n",
    "        mejor_p = 1.0\n",
    "        mejor_var = None\n",
    "        \n",
    "        for var in variables:\n",
    "            # Crear matriz con constante + variables seleccionadas + nueva variable\n",
    "            X_temp = data[seleccionadas + [var]] if seleccionadas else data[[var]]\n",
    "            X_temp = sm.add_constant(X_temp)\n",
    "            \n",
    "            modelo_temp = sm.OLS(y, X_temp).fit()\n",
    "            p_val = modelo_temp.pvalues[var]\n",
    "            \n",
    "            if p_val < mejor_p:\n",
    "                mejor_p = p_val\n",
    "                mejor_var = var\n",
    "                mejor_modelo = modelo_temp\n",
    "        \n",
    "        if mejor_p > alpha:\n",
    "            print(f\"Parando: ninguna variable tiene p-valor < {alpha}\")\n",
    "            break\n",
    "        \n",
    "        seleccionadas.append(mejor_var)\n",
    "        variables.remove(mejor_var)\n",
    "        \n",
    "        print(f\"Paso {paso}: {mejor_var} (p={mejor_p:.4f}), R²={mejor_modelo.rsquared:.4f}\")\n",
    "        paso += 1\n",
    "    \n",
    "    # Modelo final\n",
    "    if seleccionadas:\n",
    "        X_final = sm.add_constant(data[seleccionadas])\n",
    "        modelo_final = sm.OLS(y, X_final).fit()\n",
    "    else:\n",
    "        # Solo intercepto\n",
    "        X_final = sm.add_constant(pd.DataFrame(index=data.index))\n",
    "        modelo_final = sm.OLS(y, X_final).fit()\n",
    "    \n",
    "    print(f\"\\nVariables seleccionadas: {seleccionadas}\")\n",
    "    return modelo_final, seleccionadas\n",
    "\n",
    "# Ejecutar selección hacia adelante\n",
    "try:\n",
    "    print(\"MÉTODO PRINCIPAL:\")\n",
    "    print(\"=\" * 30)\n",
    "    modelo_final, variables_seleccionadas = seleccion_adelante_pvalor(datos)\n",
    "except Exception as e:\n",
    "    print(f\"Error en método principal: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575598b1-b705-485f-b048-1d5a0af9ab32",
   "metadata": {},
   "source": [
    "Usar el algoritmo de selección hacia atrás para seleccionar un \n",
    "modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370cf8f5-2639-4d5e-8a17-544f5edff311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados:\n",
      "    y    x1    x2    x3    x4  x5   x6    x7    x8    x9\n",
      "0  10  2113  1985  38.9  64.7   4  868  59.7  2205  1917\n",
      "1  11  2003  2855  38.8  61.3   3  615  55.0  2096  1575\n",
      "2  11  2957  1737  40.1  60.0  14  914  65.6  1847  2175\n",
      "3  13  2285  2905  41.6  45.3  -4  957  61.4  1903  2476\n",
      "4  10  2971  1666  39.2  53.8  15  836  66.1  1457  1866\n",
      "\n",
      "Dimensión de los datos: (28, 10)\n",
      "ANÁLISIS DEL MODELO COMPLETO:\n",
      "========================================\n",
      "R² ajustado: 0.7234\n",
      "AIC: 120.94\n",
      "\n",
      "P-valores del modelo completo:\n",
      "   x2  : 0.0004 ***\n",
      "   x8  : 0.0738  (ns)\n",
      "   x9  : 0.2225  (ns)\n",
      "   x7  : 0.3235  (ns)\n",
      "   x4  : 0.4533  (ns)\n",
      "   x6  : 0.6303  (ns)\n",
      "   x3  : 0.6427  (ns)\n",
      "   x1  : 0.6903  (ns)\n",
      "   x5  : 0.9997  (ns)\n",
      "\n",
      "============================================================\n",
      "EJECUTANDO SELECCIÓN HACIA ATRÁS MANUAL\n",
      "============================================================\n",
      "Iniciando selección hacia atrás...\n",
      "==================================================\n",
      "Modelo inicial con 9 variables: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']\n",
      "Paso 1: Se eliminó 'x5' (p-valor = 0.9997)\n",
      "   R² ajustado: 0.7380, AIC: 118.94\n",
      "   Variables restantes: ['x1', 'x2', 'x3', 'x4', 'x6', 'x7', 'x8', 'x9']\n",
      "Paso 2: Se eliminó 'x1' (p-valor = 0.6811)\n",
      "   R² ajustado: 0.7488, AIC: 117.19\n",
      "   Variables restantes: ['x2', 'x3', 'x4', 'x6', 'x7', 'x8', 'x9']\n",
      "Paso 3: Se eliminó 'x6' (p-valor = 0.6390)\n",
      "   R² ajustado: 0.7580, AIC: 115.51\n",
      "   Variables restantes: ['x2', 'x3', 'x4', 'x7', 'x8', 'x9']\n",
      "Paso 4: Se eliminó 'x3' (p-valor = 0.4514)\n",
      "   R² ajustado: 0.7625, AIC: 114.28\n",
      "   Variables restantes: ['x2', 'x4', 'x7', 'x8', 'x9']\n",
      "Paso 5: Se eliminó 'x4' (p-valor = 0.4446)\n",
      "   R² ajustado: 0.7666, AIC: 113.04\n",
      "   Variables restantes: ['x2', 'x7', 'x8', 'x9']\n",
      "Paso 6: Se eliminó 'x9' (p-valor = 0.2024)\n",
      "   R² ajustado: 0.7596, AIC: 113.06\n",
      "   Variables restantes: ['x2', 'x7', 'x8']\n",
      "\n",
      "Criterio de parada: Todas las variables tienen p-valor <= 0.05\n",
      "\n",
      "==================================================\n",
      "Selección finalizada\n",
      "Variables finales: ['x2', 'x7', 'x8']\n",
      "Fórmula final: y ~ x2 + x7 + x8\n",
      "\n",
      "Resumen del modelo final:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.760\n",
      "Method:                 Least Squares   F-statistic:                     29.44\n",
      "Date:                Sun, 07 Sep 2025   Prob (F-statistic):           3.27e-08\n",
      "Time:                        23:03:11   Log-Likelihood:                -52.532\n",
      "No. Observations:                  28   AIC:                             113.1\n",
      "Df Residuals:                      24   BIC:                             118.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.8084      7.901     -0.229      0.821     -18.115      14.498\n",
      "x2             0.0036      0.001      5.177      0.000       0.002       0.005\n",
      "x7             0.1940      0.088      2.198      0.038       0.012       0.376\n",
      "x8            -0.0048      0.001     -3.771      0.001      -0.007      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                        0.665   Durbin-Watson:                   1.492\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.578\n",
      "Skew:                           0.321   Prob(JB):                        0.749\n",
      "Kurtosis:                       2.712   Cond. No.                     7.42e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.42e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "============================================================\n",
      "COMPARACIÓN FINAL\n",
      "============================================================\n",
      "Modelo completo: 9 variables\n",
      "R² ajustado: 0.7234\n",
      "AIC: 120.94\n",
      "\n",
      "Modelo final: 3 variables\n",
      "R² ajustado: 0.7596\n",
      "AIC: 113.06\n",
      "\n",
      "Reducción de variables: 6 variables eliminadas\n",
      "Cambio en R² ajustado: +0.0362\n",
      "Cambio en AIC: -7.87\n",
      "\n",
      "Variables seleccionadas: ['x2', 'x7', 'x8']\n",
      "Variables eliminadas: ['x5', 'x4', 'x1', 'x6', 'x3', 'x9']\n",
      "\n",
      "SIGNIFICANCIA DE VARIABLES FINALES:\n",
      "----------------------------------------\n",
      "x2  : p = 0.0000 ***\n",
      "x8  : p = 0.0009 ***\n",
      "x7  : p = 0.0378 *\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar los datos\n",
    "datos = pd.read_csv(\"Liga_nacional_de_futbol.csv\")\n",
    "print(\"Datos cargados:\")\n",
    "print(datos.head())\n",
    "print(f\"\\nDimensión de los datos: {datos.shape}\")\n",
    "\n",
    "def seleccion_atras_manual(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Implementa selección hacia atrás basada en p-valores\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame con los datos\n",
    "    alpha: nivel de significancia para mantener variables\n",
    "    \n",
    "    Returns:\n",
    "    modelo_final: modelo statsmodels con variables seleccionadas\n",
    "    variables_seleccionadas: lista de variables seleccionadas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Empezar con todas las variables (excluyendo y)\n",
    "    variables_actuales = [col for col in data.columns if col != 'y']\n",
    "    y = data['y']\n",
    "    \n",
    "    print(\"Iniciando selección hacia atrás...\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Modelo inicial con {len(variables_actuales)} variables: {variables_actuales}\")\n",
    "    \n",
    "    # Modelo completo inicial\n",
    "    X_completo = sm.add_constant(data[variables_actuales])\n",
    "    modelo_actual = sm.OLS(y, X_completo).fit()\n",
    "    \n",
    "    paso = 1\n",
    "    cambios = True\n",
    "    \n",
    "    while cambios and len(variables_actuales) > 0:\n",
    "        cambios = False\n",
    "        \n",
    "        # Obtener p-valores del modelo actual (excluyendo constante)\n",
    "        pvalores = modelo_actual.pvalues.drop('const', errors='ignore')\n",
    "        \n",
    "        # Encontrar la variable con el p-valor más alto\n",
    "        if len(pvalores) > 0:\n",
    "            peor_pvalor = pvalores.max()\n",
    "            peor_variable = pvalores.idxmax()\n",
    "            \n",
    "            # Verificar criterio de eliminación\n",
    "            if peor_pvalor > alpha:\n",
    "                # Eliminar la variable con p-valor más alto\n",
    "                variables_actuales.remove(peor_variable)\n",
    "                \n",
    "                # Ajustar nuevo modelo\n",
    "                if len(variables_actuales) > 0:\n",
    "                    X_nuevo = sm.add_constant(data[variables_actuales])\n",
    "                    modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "                else:\n",
    "                    # Solo intercepto\n",
    "                    X_nuevo = sm.add_constant(pd.DataFrame())\n",
    "                    modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "                \n",
    "                cambios = True\n",
    "                \n",
    "                print(f\"Paso {paso}: Se eliminó '{peor_variable}' (p-valor = {peor_pvalor:.4f})\")\n",
    "                print(f\"   R² ajustado: {modelo_nuevo.rsquared_adj:.4f}, AIC: {modelo_nuevo.aic:.2f}\")\n",
    "                print(f\"   Variables restantes: {variables_actuales}\")\n",
    "                \n",
    "                modelo_actual = modelo_nuevo\n",
    "                paso += 1\n",
    "            else:\n",
    "                print(f\"\\nCriterio de parada: Todas las variables tienen p-valor <= {alpha}\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Selección finalizada\")\n",
    "    print(f\"Variables finales: {variables_actuales}\")\n",
    "    \n",
    "    if variables_actuales:\n",
    "        print(f\"Fórmula final: y ~ {' + '.join(variables_actuales)}\")\n",
    "    else:\n",
    "        print(\"Fórmula final: y ~ 1 (solo intercepto)\")\n",
    "    \n",
    "    print(\"\\nResumen del modelo final:\")\n",
    "    print(modelo_actual.summary())\n",
    "    \n",
    "    return modelo_actual, variables_actuales\n",
    "\n",
    "def seleccion_atras_detallada(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Versión más detallada con información adicional en cada paso\n",
    "    \"\"\"\n",
    "    variables_actuales = [col for col in data.columns if col != 'y']\n",
    "    y = data['y']\n",
    "    \n",
    "    print(\"Selección hacia atrás - Versión detallada\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Modelo completo inicial\n",
    "    X_completo = sm.add_constant(data[variables_actuales])\n",
    "    modelo_actual = sm.OLS(y, X_completo).fit()\n",
    "    \n",
    "    print(f\"Modelo inicial - R² ajustado: {modelo_actual.rsquared_adj:.4f}\")\n",
    "    print(\"P-valores iniciales:\")\n",
    "    for var, pval in modelo_actual.pvalues.drop('const').items():\n",
    "        print(f\"   {var}: {pval:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    paso = 1\n",
    "    \n",
    "    while len(variables_actuales) > 0:\n",
    "        pvalores = modelo_actual.pvalues.drop('const', errors='ignore')\n",
    "        \n",
    "        if len(pvalores) == 0:\n",
    "            break\n",
    "            \n",
    "        peor_pvalor = pvalores.max()\n",
    "        peor_variable = pvalores.idxmax()\n",
    "        \n",
    "        if peor_pvalor <= alpha:\n",
    "            print(f\"Todas las variables significativas (p <= {alpha}). Parando.\")\n",
    "            break\n",
    "        \n",
    "        # Eliminar variable\n",
    "        variables_actuales.remove(peor_variable)\n",
    "        \n",
    "        # Ajustar nuevo modelo\n",
    "        if variables_actuales:\n",
    "            X_nuevo = sm.add_constant(data[variables_actuales])\n",
    "            modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "        else:\n",
    "            X_nuevo = sm.add_constant(pd.DataFrame(index=data.index))\n",
    "            modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "        \n",
    "        print(f\"--- Paso {paso} ---\")\n",
    "        print(f\"Eliminada: {peor_variable} (p-valor: {peor_pvalor:.4f})\")\n",
    "        print(f\"R² ajustado: {modelo_nuevo.rsquared_adj:.4f} (cambio: {modelo_nuevo.rsquared_adj - modelo_actual.rsquared_adj:+.4f})\")\n",
    "        print(f\"AIC: {modelo_nuevo.aic:.2f} (cambio: {modelo_nuevo.aic - modelo_actual.aic:+.2f})\")\n",
    "        print(f\"Variables restantes: {len(variables_actuales)}\")\n",
    "        \n",
    "        if variables_actuales:\n",
    "            print(\"P-valores actuales:\")\n",
    "            for var, pval in modelo_nuevo.pvalues.drop('const').items():\n",
    "                print(f\"   {var}: {pval:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        modelo_actual = modelo_nuevo\n",
    "        paso += 1\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"PROCESO FINALIZADO\")\n",
    "    print(f\"Variables seleccionadas: {variables_actuales}\")\n",
    "    return modelo_actual, variables_actuales\n",
    "\n",
    "def analizar_modelo_completo(data):\n",
    "    \"\"\"\n",
    "    Análisis del modelo completo para referencia\n",
    "    \"\"\"\n",
    "    y = data['y']\n",
    "    X_variables = [col for col in data.columns if col != 'y']\n",
    "    X = sm.add_constant(data[X_variables])\n",
    "    \n",
    "    modelo_completo = sm.OLS(y, X).fit()\n",
    "    \n",
    "    print(\"ANÁLISIS DEL MODELO COMPLETO:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"R² ajustado: {modelo_completo.rsquared_adj:.4f}\")\n",
    "    print(f\"AIC: {modelo_completo.aic:.2f}\")\n",
    "    print(\"\\nP-valores del modelo completo:\")\n",
    "    \n",
    "    pvalores = modelo_completo.pvalues.drop('const')\n",
    "    for var, pval in pvalores.sort_values().items():\n",
    "        significancia = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \" (ns)\"\n",
    "        print(f\"   {var:4}: {pval:.4f} {significancia}\")\n",
    "    \n",
    "    return modelo_completo\n",
    "\n",
    "# Ejecutar el análisis del modelo completo primero\n",
    "modelo_completo = analizar_modelo_completo(datos)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJECUTANDO SELECCIÓN HACIA ATRÁS MANUAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ejecutar selección hacia atrás\n",
    "try:\n",
    "    modelo_final, variables_finales = seleccion_atras_manual(datos, alpha=0.05)\n",
    "except Exception as e:\n",
    "    print(f\"Error en el método principal: {e}\")\n",
    "    print(\"Ejecutando versión alternativa...\")\n",
    "    modelo_final, variables_finales = seleccion_atras_detallada(datos, alpha=0.05)\n",
    "\n",
    "# Comparación final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARACIÓN FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Modelo completo: {len([col for col in datos.columns if col != 'y'])} variables\")\n",
    "print(f\"R² ajustado: {modelo_completo.rsquared_adj:.4f}\")\n",
    "print(f\"AIC: {modelo_completo.aic:.2f}\")\n",
    "\n",
    "print(f\"\\nModelo final: {len(variables_finales)} variables\")\n",
    "print(f\"R² ajustado: {modelo_final.rsquared_adj:.4f}\")\n",
    "print(f\"AIC: {modelo_final.aic:.2f}\")\n",
    "\n",
    "print(f\"\\nReducción de variables: {len([col for col in datos.columns if col != 'y']) - len(variables_finales)} variables eliminadas\")\n",
    "print(f\"Cambio en R² ajustado: {modelo_final.rsquared_adj - modelo_completo.rsquared_adj:+.4f}\")\n",
    "print(f\"Cambio en AIC: {modelo_final.aic - modelo_completo.aic:+.2f}\")\n",
    "\n",
    "# Mostrar variables eliminadas vs seleccionadas\n",
    "variables_todas = [col for col in datos.columns if col != 'y']\n",
    "variables_eliminadas = list(set(variables_todas) - set(variables_finales))\n",
    "\n",
    "print(f\"\\nVariables seleccionadas: {variables_finales}\")\n",
    "print(f\"Variables eliminadas: {variables_eliminadas}\")\n",
    "\n",
    "# Análisis de significancia de las variables finales\n",
    "if variables_finales:\n",
    "    print(\"\\nSIGNIFICANCIA DE VARIABLES FINALES:\")\n",
    "    print(\"-\" * 40)\n",
    "    pvalores_finales = modelo_final.pvalues.drop('const', errors='ignore')\n",
    "    for var, pval in pvalores_finales.sort_values().items():\n",
    "        sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \" (ns)\"\n",
    "        print(f\"{var:4}: p = {pval:.4f} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef55ce7-6b7d-42d4-92a6-0358e7ef3740",
   "metadata": {},
   "source": [
    "C) Usar el algoritmo de regresión por pasos para seleccionar un modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ec790a-8878-45ad-a8df-7c6854760bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados:\n",
      "    y    x1    x2    x3    x4  x5   x6    x7    x8    x9\n",
      "0  10  2113  1985  38.9  64.7   4  868  59.7  2205  1917\n",
      "1  11  2003  2855  38.8  61.3   3  615  55.0  2096  1575\n",
      "2  11  2957  1737  40.1  60.0  14  914  65.6  1847  2175\n",
      "3  13  2285  2905  41.6  45.3  -4  957  61.4  1903  2476\n",
      "4  10  2971  1666  39.2  53.8  15  836  66.1  1457  1866\n",
      "\n",
      "Dimensión de los datos: (28, 10)\n",
      "Error en el proceso principal: name 'analizar_proceso_completo' is not defined\n",
      "Ejecutando método stepwise directamente...\n",
      "Iniciando regresión por pasos manual...\n",
      "============================================================\n",
      "Criterios: Entrada (p < 0.05), Salida (p > 0.1)\n",
      "\n",
      "--- Paso 1: Fase de entrada ---\n",
      "   ENTRADA: Se agregó 'x8' (p = 0.0000)\n",
      "   R² ajustado: 0.5272, AIC: 130.25\n",
      "   Variables en modelo: ['x8']\n",
      "--- Paso 2: Fase de entrada ---\n",
      "   ENTRADA: Se agregó 'x2' (p = 0.0002)\n",
      "   R² ajustado: 0.7227, AIC: 116.20\n",
      "   Variables en modelo: ['x8', 'x2']\n",
      "--- Paso 3: Fase de entrada ---\n",
      "   ENTRADA: Se agregó 'x7' (p = 0.0378)\n",
      "   R² ajustado: 0.7596, AIC: 113.06\n",
      "   Variables en modelo: ['x8', 'x2', 'x7']\n",
      "--- Paso 4: Fase de entrada ---\n",
      "   No hay variables para entrada (mejor p = 0.2024 >= 0.05)\n",
      "--- Paso 4: Fase de salida ---\n",
      "   Ninguna variable cumple criterio de salida (peor p = 0.0378 <= 0.1)\n",
      "No se pueden agregar más variables (p >= 0.05) y no se pueden eliminar (p <= 0.1)\n",
      "\n",
      "============================================================\n",
      "Regresión por pasos finalizada\n",
      "Variables finales: ['x8', 'x2', 'x7']\n",
      "Fórmula final: y ~ x8 + x2 + x7\n",
      "\n",
      "Resumen del modelo final:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.760\n",
      "Method:                 Least Squares   F-statistic:                     29.44\n",
      "Date:                Sun, 07 Sep 2025   Prob (F-statistic):           3.27e-08\n",
      "Time:                        23:20:26   Log-Likelihood:                -52.532\n",
      "No. Observations:                  28   AIC:                             113.1\n",
      "Df Residuals:                      24   BIC:                             118.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.8084      7.901     -0.229      0.821     -18.115      14.498\n",
      "x8            -0.0048      0.001     -3.771      0.001      -0.007      -0.002\n",
      "x2             0.0036      0.001      5.177      0.000       0.002       0.005\n",
      "x7             0.1940      0.088      2.198      0.038       0.012       0.376\n",
      "==============================================================================\n",
      "Omnibus:                        0.665   Durbin-Watson:                   1.492\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.578\n",
      "Skew:                           0.321   Prob(JB):                        0.749\n",
      "Kurtosis:                       2.712   Cond. No.                     7.42e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.42e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar los datos\n",
    "datos = pd.read_csv(\"Liga_nacional_de_futbol.csv\")\n",
    "print(\"Datos cargados:\")\n",
    "print(datos.head())\n",
    "print(f\"\\nDimensión de los datos: {datos.shape}\")\n",
    "\n",
    "def regresion_por_pasos_manual(data, alpha_entrada=0.05, alpha_salida=0.10):\n",
    "    \"\"\"\n",
    "    Implementa regresión por pasos manual (stepwise)\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame con los datos\n",
    "    alpha_entrada: umbral para entrada de variables\n",
    "    alpha_salida: umbral para salida de variables\n",
    "    \n",
    "    Returns:\n",
    "    modelo_final: modelo statsmodels con variables seleccionadas\n",
    "    variables_modelo: lista de variables seleccionadas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Variables disponibles (excluyendo y)\n",
    "    variables_disponibles = [col for col in data.columns if col != 'y']\n",
    "    variables_modelo = []\n",
    "    y = data['y']\n",
    "    \n",
    "    print(\"Iniciando regresión por pasos manual...\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Criterios: Entrada (p < {alpha_entrada}), Salida (p > {alpha_salida})\")\n",
    "    print()\n",
    "    \n",
    "    # Modelo inicial con solo intercepto\n",
    "    X_const = sm.add_constant(pd.DataFrame(index=data.index))\n",
    "    modelo_actual = sm.OLS(y, X_const).fit()\n",
    "    \n",
    "    paso = 1\n",
    "    cambios = True\n",
    "    \n",
    "    while cambios:\n",
    "        cambios = False\n",
    "        \n",
    "        # FASE 1: ENTRADA (FORWARD)\n",
    "        if variables_disponibles:\n",
    "            print(f\"--- Paso {paso}: Fase de entrada ---\")\n",
    "            \n",
    "            mejor_p_entrada = float('inf')\n",
    "            mejor_var_entrada = None\n",
    "            mejor_modelo_entrada = None\n",
    "            \n",
    "            # Probar cada variable disponible para entrada\n",
    "            for variable in variables_disponibles:\n",
    "                # Crear matriz de diseño con variables actuales + nueva variable\n",
    "                if variables_modelo:\n",
    "                    X_temp = data[variables_modelo + [variable]].copy()\n",
    "                else:\n",
    "                    X_temp = data[[variable]].copy()\n",
    "                \n",
    "                X_temp = sm.add_constant(X_temp)\n",
    "                \n",
    "                # Ajustar modelo temporal\n",
    "                modelo_temp = sm.OLS(y, X_temp).fit()\n",
    "                \n",
    "                # Obtener p-valor de la nueva variable\n",
    "                pvalor_nuevo = modelo_temp.pvalues[variable]\n",
    "                \n",
    "                # Verificar si es la mejor candidata para entrada\n",
    "                if pvalor_nuevo < mejor_p_entrada:\n",
    "                    mejor_p_entrada = pvalor_nuevo\n",
    "                    mejor_var_entrada = variable\n",
    "                    mejor_modelo_entrada = modelo_temp\n",
    "            \n",
    "            # Verificar criterio de entrada\n",
    "            if mejor_p_entrada < alpha_entrada:\n",
    "                # Agregar variable al modelo\n",
    "                variables_modelo.append(mejor_var_entrada)\n",
    "                variables_disponibles.remove(mejor_var_entrada)\n",
    "                modelo_actual = mejor_modelo_entrada\n",
    "                \n",
    "                print(f\"   ENTRADA: Se agregó '{mejor_var_entrada}' (p = {mejor_p_entrada:.4f})\")\n",
    "                print(f\"   R² ajustado: {modelo_actual.rsquared_adj:.4f}, AIC: {modelo_actual.aic:.2f}\")\n",
    "                print(f\"   Variables en modelo: {variables_modelo}\")\n",
    "                \n",
    "                cambios = True\n",
    "                paso += 1\n",
    "                continue  # Ir al siguiente paso después de una entrada\n",
    "            else:\n",
    "                print(f\"   No hay variables para entrada (mejor p = {mejor_p_entrada:.4f} >= {alpha_entrada})\")\n",
    "        \n",
    "        # FASE 2: SALIDA (BACKWARD)\n",
    "        if variables_modelo:\n",
    "            print(f\"--- Paso {paso}: Fase de salida ---\")\n",
    "            \n",
    "            # Obtener p-valores del modelo actual (excluyendo constante)\n",
    "            pvalores_actuales = modelo_actual.pvalues.drop('const', errors='ignore')\n",
    "            \n",
    "            if not pvalores_actuales.empty:\n",
    "                # Encontrar variable con mayor p-valor\n",
    "                peor_p_salida = pvalores_actuales.max()\n",
    "                peor_var_salida = pvalores_actuales.idxmax()\n",
    "                \n",
    "                # Verificar criterio de salida\n",
    "                if peor_p_salida > alpha_salida:\n",
    "                    # Eliminar variable del modelo\n",
    "                    variables_modelo.remove(peor_var_salida)\n",
    "                    variables_disponibles.append(peor_var_salida)\n",
    "                    \n",
    "                    # Ajustar nuevo modelo\n",
    "                    if variables_modelo:\n",
    "                        X_nuevo = sm.add_constant(data[variables_modelo])\n",
    "                        modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "                    else:\n",
    "                        X_nuevo = sm.add_constant(pd.DataFrame(index=data.index))\n",
    "                        modelo_nuevo = sm.OLS(y, X_nuevo).fit()\n",
    "                    \n",
    "                    print(f\"   SALIDA: Se eliminó '{peor_var_salida}' (p = {peor_p_salida:.4f})\")\n",
    "                    print(f\"   R² ajustado: {modelo_nuevo.rsquared_adj:.4f}, AIC: {modelo_nuevo.aic:.2f}\")\n",
    "                    print(f\"   Variables en modelo: {variables_modelo}\")\n",
    "                    \n",
    "                    modelo_actual = modelo_nuevo\n",
    "                    cambios = True\n",
    "                    paso += 1\n",
    "                else:\n",
    "                    print(f\"   Ninguna variable cumple criterio de salida (peor p = {peor_p_salida:.4f} <= {alpha_salida})\")\n",
    "            else:\n",
    "                print(\"   No hay variables para evaluar salida\")\n",
    "        \n",
    "        # Si no hubo cambios en ninguna fase, terminar\n",
    "        if not cambios:\n",
    "            if variables_disponibles:\n",
    "                print(f\"No se pueden agregar más variables (p >= {alpha_entrada}) y no se pueden eliminar (p <= {alpha_salida})\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Regresión por pasos finalizada\")\n",
    "    print(f\"Variables finales: {variables_modelo}\")\n",
    "    \n",
    "    if variables_modelo:\n",
    "        print(f\"Fórmula final: y ~ {' + '.join(variables_modelo)}\")\n",
    "    else:\n",
    "        print(\"Fórmula final: y ~ 1 (solo intercepto)\")\n",
    "    \n",
    "    # Ajustar modelo final para asegurar consistencia\n",
    "    if variables_modelo:\n",
    "        X_final = sm.add_constant(data[variables_modelo])\n",
    "        modelo_final = sm.OLS(y, X_final).fit()\n",
    "    else:\n",
    "        X_final = sm.add_constant(pd.DataFrame(index=data.index))\n",
    "        modelo_final = sm.OLS(y, X_final).fit()\n",
    "    \n",
    "    print(\"\\nResumen del modelo final:\")\n",
    "    print(modelo_final.summary())\n",
    "    \n",
    "    return modelo_final, variables_modelo\n",
    "\n",
    "# Ejecutar el análisis completo\n",
    "try:\n",
    "    modelo_final, variables_finales = analizar_proceso_completo(datos)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error en el proceso principal: {e}\")\n",
    "    print(\"Ejecutando método stepwise directamente...\")\n",
    "    modelo_final, variables_finales = regresion_por_pasos_manual(datos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd76bc-099e-4fc6-afaf-3ec835e3cb69",
   "metadata": {},
   "source": [
    " ****************************************************************************\n",
    " D) Comenta los modelos finales en cada uno de los casos anteriores. ¿Cuál tiene \n",
    " más sentido? ¿Cuál modelo usarían?\n",
    " ****************************************************************************\n",
    "\n",
    "\n",
    " En cada caso se llega al mismo modelo, con las variables x8, x2 y x7. Yo utilizaría\n",
    " el algoritmo de selección por pasos, por eficiente y por superar algunas de las\n",
    " limitaciones del forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
